{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c393470",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load necessary modules\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.tools import *\n",
    "from utils.losses import *\n",
    "from models.mnist import *\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb902559",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper-parameters\n",
    "random_seed = 2020\n",
    "critic_iter = 10\n",
    "critic_iter_d = 10\n",
    "epochs = 100\n",
    "std = 0.1\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0.0\n",
    "batch_size = 250\n",
    "z_dim = 8\n",
    "structure_dim = 128\n",
    "d_dim = 512\n",
    "g_dim = 512\n",
    "lambda_mmd = 10.0\n",
    "lambda_gp = 5.0\n",
    "lambda_power = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53617817",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "# torch.manual_seed(random_seed)\n",
    "cuda_available = torch.cuda.is_available()  # check if gpu is available\n",
    "\n",
    "## initialize models\n",
    "netI = I_MNIST()\n",
    "netI = netI.cuda() if cuda_available else netI\n",
    "netG = G_MNIST()\n",
    "netG = netG.cuda() if cuda_available else netG\n",
    "netD = D_MNIST()\n",
    "netD = netD.cuda() if cuda_available else netD\n",
    "\n",
    "## set up optimizers\n",
    "optim_I = optim.Adam(netI.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optim_G = optim.Adam(netG.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optim_D = optim.Adam(netD.parameters(), lr=learning_rate * 10, betas=(0.5, 0.999), \n",
    "                     weight_decay=weight_decay)\n",
    "\n",
    "## load datasets\n",
    "# train_gen, dev_gen, test_gen = load(batch_size, batch_size)\n",
    "# data = inf_train_gen_mnist(train_gen)\n",
    "transform    = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_gen    = dsets.MNIST(root=\"./datasets\",train=True, transform=transform, download=True)\n",
    "test_gen     = dsets.MNIST(root=\"./datasets\",train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_gen, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "## initial empty lists for training progress\n",
    "primal_loss_GI = []\n",
    "dual_loss_GI = []\n",
    "# primal_loss = []\n",
    "# dual_loss = []\n",
    "# primal_loss_z = []\n",
    "loss_mmd = []\n",
    "gp = []\n",
    "re = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de72efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yye1997/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:952: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv_transpose2d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GI: 31.49949836730957\n",
      "D: 31.500247955322266\n",
      "GI: 28.112903594970703\n",
      "D: 28.106735229492188\n",
      "GI: 27.7220516204834\n",
      "D: 27.701404571533203\n",
      "GI: 27.39789581298828\n",
      "D: 27.427082061767578\n",
      "GI: 27.248533248901367\n",
      "D: 27.222490310668945\n",
      "GI: 27.159019470214844\n",
      "D: 27.18914222717285\n",
      "GI: 27.106067657470703\n",
      "D: 27.09993553161621\n",
      "GI: 27.051029205322266\n",
      "D: 27.068084716796875\n",
      "GI: 27.05169105529785\n",
      "D: 27.028879165649414\n",
      "GI: 27.01833724975586\n",
      "D: 27.010408401489258\n",
      "GI: 27.020153045654297\n",
      "D: 26.967164993286133\n",
      "GI: 26.983808517456055\n",
      "D: 27.015954971313477\n",
      "GI: 26.978130340576172\n",
      "D: 27.003190994262695\n",
      "GI: 26.983919143676758\n",
      "D: 26.974637985229492\n",
      "GI: 26.962158203125\n",
      "D: 26.969371795654297\n",
      "GI: 26.949581146240234\n",
      "D: 26.975534439086914\n",
      "GI: 26.93528175354004\n",
      "D: 26.939306259155273\n",
      "GI: 26.934711456298828\n",
      "D: 26.937637329101562\n",
      "GI: 26.948707580566406\n",
      "D: 26.923080444335938\n",
      "GI: 26.954662322998047\n",
      "D: 26.93804359436035\n",
      "GI: 26.946836471557617\n",
      "D: 26.92667007446289\n",
      "GI: 26.93946075439453\n",
      "D: 26.973037719726562\n",
      "GI: 26.922712326049805\n",
      "D: 26.939966201782227\n",
      "GI: 26.94377899169922\n",
      "D: 26.93114471435547\n",
      "GI: 26.9252986907959\n",
      "D: 26.93056297302246\n",
      "GI: 26.92628288269043\n",
      "D: 26.940887451171875\n",
      "GI: 26.96804428100586\n",
      "D: 26.931926727294922\n",
      "GI: 26.920454025268555\n",
      "D: 26.942392349243164\n",
      "GI: 26.916748046875\n",
      "D: 26.920289993286133\n",
      "GI: 26.94886016845703\n",
      "D: 26.94085693359375\n",
      "GI: 26.91473960876465\n",
      "D: 26.943531036376953\n",
      "GI: 26.91374969482422\n",
      "D: 26.916912078857422\n",
      "GI: 26.9326114654541\n",
      "D: 26.908447265625\n",
      "GI: 26.962594985961914\n",
      "D: 26.944499969482422\n",
      "GI: 26.936771392822266\n",
      "D: 26.966421127319336\n",
      "GI: 26.903478622436523\n",
      "D: 26.969194412231445\n",
      "GI: 26.926834106445312\n",
      "D: 26.985578536987305\n",
      "GI: 26.913558959960938\n",
      "D: 26.965248107910156\n",
      "GI: 26.923580169677734\n",
      "D: 26.947507858276367\n",
      "GI: 26.929119110107422\n",
      "D: 26.953907012939453\n",
      "GI: 26.918373107910156\n",
      "D: 26.94679832458496\n",
      "GI: 26.935564041137695\n",
      "D: 26.96079444885254\n",
      "GI: 26.95298957824707\n",
      "D: 26.920228958129883\n",
      "GI: 26.916006088256836\n",
      "D: 26.93822479248047\n",
      "GI: 26.91452407836914\n",
      "D: 26.935590744018555\n",
      "GI: 26.959415435791016\n",
      "D: 26.943105697631836\n",
      "GI: 26.925783157348633\n",
      "D: 26.91692543029785\n",
      "GI: 26.93343162536621\n",
      "D: 26.94046974182129\n",
      "GI: 26.930938720703125\n",
      "D: 26.946624755859375\n",
      "GI: 26.956188201904297\n",
      "D: 26.916187286376953\n",
      "GI: 26.903188705444336\n",
      "D: 26.94461441040039\n",
      "GI: 26.933269500732422\n",
      "D: 26.9189510345459\n",
      "GI: 26.921390533447266\n",
      "D: 26.942489624023438\n",
      "GI: 26.976072311401367\n",
      "D: 26.95059585571289\n",
      "GI: 26.926868438720703\n",
      "D: 26.927488327026367\n",
      "GI: 26.925086975097656\n",
      "D: 26.93874740600586\n",
      "GI: 26.935062408447266\n",
      "D: 26.955703735351562\n",
      "GI: 26.943742752075195\n",
      "D: 26.93720817565918\n",
      "GI: 26.953969955444336\n",
      "D: 26.939043045043945\n",
      "GI: 26.96537208557129\n",
      "D: 26.93745231628418\n",
      "GI: 26.919458389282227\n",
      "D: 26.956310272216797\n",
      "GI: 26.94345474243164\n",
      "D: 26.90264129638672\n",
      "GI: 26.94108009338379\n",
      "D: 26.944307327270508\n",
      "GI: 26.9216251373291\n",
      "D: 26.917551040649414\n",
      "GI: 26.938642501831055\n",
      "D: 26.938051223754883\n",
      "GI: 26.966012954711914\n",
      "D: 26.94803237915039\n",
      "GI: 26.95299530029297\n",
      "D: 26.907150268554688\n",
      "GI: 26.943408966064453\n",
      "D: 26.943525314331055\n",
      "GI: 26.952146530151367\n",
      "D: 26.948402404785156\n",
      "GI: 26.927978515625\n",
      "D: 26.915081024169922\n",
      "GI: 26.939939498901367\n",
      "D: 26.939176559448242\n",
      "GI: 26.91904067993164\n",
      "D: 26.9300479888916\n",
      "GI: 26.88666534423828\n",
      "D: 26.95588493347168\n",
      "GI: 26.957345962524414\n",
      "D: 26.945903778076172\n",
      "GI: 26.940105438232422\n",
      "D: 26.944543838500977\n",
      "GI: 26.916263580322266\n",
      "D: 26.92375946044922\n",
      "GI: 26.921892166137695\n",
      "D: 26.938461303710938\n",
      "GI: 26.93848991394043\n",
      "D: 26.927001953125\n",
      "GI: 26.912981033325195\n",
      "D: 26.914522171020508\n",
      "GI: 26.923587799072266\n",
      "D: 26.933765411376953\n",
      "GI: 26.952096939086914\n",
      "D: 26.928852081298828\n",
      "GI: 26.893884658813477\n",
      "D: 26.951162338256836\n",
      "GI: 26.900638580322266\n",
      "D: 26.967456817626953\n",
      "GI: 26.94308090209961\n",
      "D: 26.970590591430664\n",
      "GI: 26.927654266357422\n",
      "D: 26.93250846862793\n",
      "GI: 26.930580139160156\n",
      "D: 26.921173095703125\n",
      "GI: 26.943145751953125\n",
      "D: 26.936681747436523\n",
      "GI: 26.951993942260742\n",
      "D: 26.95151710510254\n",
      "GI: 26.937105178833008\n",
      "D: 26.939607620239258\n",
      "GI: 26.92364501953125\n",
      "D: 26.94196128845215\n",
      "GI: 26.92669105529785\n",
      "D: 26.933076858520508\n",
      "GI: 26.9389591217041\n",
      "D: 26.93461036682129\n",
      "GI: 26.922971725463867\n",
      "D: 26.92884635925293\n",
      "GI: 26.903539657592773\n",
      "D: 26.919898986816406\n",
      "GI: 26.946033477783203\n",
      "D: 26.91034698486328\n",
      "GI: 26.9567813873291\n",
      "D: 26.966123580932617\n",
      "GI: 26.92363739013672\n",
      "D: 26.93266487121582\n",
      "GI: 26.92860984802246\n",
      "D: 26.944442749023438\n",
      "GI: 26.950618743896484\n",
      "D: 26.960023880004883\n",
      "GI: 26.934049606323242\n",
      "D: 26.961021423339844\n"
     ]
    }
   ],
   "source": [
    "# ************************\n",
    "# *** iWGANs Algorithm ***\n",
    "# ************************\n",
    "z_sample = torch.randn(batch_size, z_dim)\n",
    "z_sample = z_sample.cuda() if cuda_available else z_sample\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    data = iter(train_loader)\n",
    "    # 1. Update G, I network\n",
    "    # (1). Set up parameters of G, I to update\n",
    "    #      set up parameters of D to freeze\n",
    "    for p in netD.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in netI.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in netG.parameters():\n",
    "        p.requires_grad = True\n",
    "    # (2). Update G and I\n",
    "    for _ in range(critic_iter):\n",
    "        images, _ = next(data)\n",
    "        images = images.view(batch_size, 784)\n",
    "        real_data = images.cuda() if cuda_available else images\n",
    "        noise = torch.randn(batch_size, z_dim)\n",
    "        noise = noise.cuda() if cuda_available else noise\n",
    "        fake_data = netG(noise)\n",
    "        netI.zero_grad()\n",
    "        netG.zero_grad()\n",
    "        cost_GI = GI_loss(netI, netG, netD, real_data, fake_data)\n",
    "        images, _ = next(data)\n",
    "        x = images.view(batch_size, 784)\n",
    "        x = x.cuda() if cuda_available else x\n",
    "        z = torch.randn(batch_size, z_dim)\n",
    "        z = z.cuda() if cuda_available else z\n",
    "        z_hat = netI(x)\n",
    "        mmd = mmd_penalty(z_hat, z, kernel=\"IMQ\")\n",
    "        primal_cost = cost_GI + lambda_mmd * mmd\n",
    "        primal_cost.backward()\n",
    "        optim_I.step()\n",
    "        optim_G.step()\n",
    "    print('GI: '+str(primal(netI, netG, netD, real_data).cpu().item()))\n",
    "    # (3). Append primal and dual loss to list\n",
    "    primal_loss_GI.append(primal(netI, netG, netD, real_data).cpu().item())\n",
    "    dual_loss_GI.append(dual(netI, netG, netD, real_data, fake_data).cpu().item())\n",
    "    # 2. Update D network\n",
    "    # (1). Set up parameters of D to update\n",
    "    #      set up parameters of G, I to freeze\n",
    "    for p in netD.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in netI.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in netG.parameters():\n",
    "        p.requires_grad = False\n",
    "    # (2). Update D\n",
    "    for _ in range(critic_iter_d):\n",
    "#         _data = next(data)\n",
    "#         real_data = torch.Tensor(_data)\n",
    "#         real_data = real_data.cuda() if cuda_available else real_data\n",
    "        images, labels = next(data)\n",
    "        images = images.view(batch_size, 784)\n",
    "        real_data = images.cuda() if cuda_available else images\n",
    "        noise = torch.randn(batch_size, z_dim)\n",
    "        noise = noise.cuda() if cuda_available else noise\n",
    "        fake_data = netG(noise)\n",
    "        netD.zero_grad()\n",
    "        cost_D = D_loss(netI, netG, netD, real_data, fake_data)\n",
    "        images, _ = next(data)\n",
    "        x = images.view(batch_size, 784)\n",
    "        x = x.cuda() if cuda_available else x\n",
    "        z = torch.randn(batch_size, z_dim)\n",
    "        z = z.cuda() if cuda_available else z\n",
    "        z_hat = netI(x)\n",
    "        gp_D = gradient_penalty_dual(x.data, z.data, netD, netG, netI)\n",
    "        dual_cost = cost_D + lambda_gp * gp_D\n",
    "        dual_cost.backward()\n",
    "        optim_D.step()\n",
    "        loss_mmd.append(mmd.cpu().item())\n",
    "#         print(gp_D.cpu().item())\n",
    "    print('D: '+str(primal(netI, netG, netD, real_data).cpu().item()))\n",
    "    gp.append(gp_D.cpu().item())\n",
    "    re.append(primal(netI, netG, netD, real_data).cpu().item())\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        torchvision.utils.save_image(netG(z_sample).view(-1, 1, 28, 28)[:25], \"./outputs/MNIST/fake\" + str(epoch) + \".png\", nrow=5)\n",
    "        torchvision.utils.save_image(images[:25], \"./outputs/MNIST/real.png\", nrow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb1835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(primal_loss_GI)\n",
    "# print(dual_loss_GI)\n",
    "# print(loss_mmd)\n",
    "# print(gp)\n",
    "# print(re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
