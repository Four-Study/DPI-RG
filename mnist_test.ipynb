{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c393470",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load necessary modules\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.tools import *\n",
    "from utils.losses import *\n",
    "from models.mnist import *\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb902559",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper-parameters\n",
    "random_seed = 2020\n",
    "critic_iter = 10\n",
    "critic_iter_d = 10\n",
    "epochs = 100\n",
    "std = 0.1\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0.0\n",
    "batch_size = 500\n",
    "z_dim = 8\n",
    "structure_dim = 128\n",
    "d_dim = 512\n",
    "g_dim = 512\n",
    "lambda_mmd = 10.0\n",
    "lambda_gp = 5.0\n",
    "lambda_power = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53617817",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "# torch.manual_seed(random_seed)\n",
    "cuda_available = torch.cuda.is_available()  # check if gpu is available\n",
    "\n",
    "## initialize models\n",
    "netI = I_MNIST()\n",
    "netI = netI.cuda() if cuda_available else netI\n",
    "netG = G_MNIST()\n",
    "netG = netG.cuda() if cuda_available else netG\n",
    "netD = D_MNIST()\n",
    "netD = netD.cuda() if cuda_available else netD\n",
    "\n",
    "## set up optimizers\n",
    "optim_I = optim.Adam(netI.parameters(), lr=learning_rate)\n",
    "optim_G = optim.Adam(netG.parameters(), lr=learning_rate)\n",
    "optim_D = optim.Adam(netD.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "## load datasets\n",
    "# train_gen, dev_gen, test_gen = load(batch_size, batch_size)\n",
    "# data = inf_train_gen_mnist(train_gen)\n",
    "transform    = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_gen    = dsets.MNIST(root=\"./datasets\",train=True, transform=transform, download=True)\n",
    "test_gen     = dsets.MNIST(root=\"./datasets\",train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_gen, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "## initial empty lists for training progress\n",
    "primal_loss_GI = []\n",
    "dual_loss_GI = []\n",
    "# primal_loss = []\n",
    "# dual_loss = []\n",
    "# primal_loss_z = []\n",
    "loss_mmd = []\n",
    "gp = []\n",
    "re = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de72efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yye1997/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:952: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv_transpose2d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GI: 27.129621505737305\n",
      "D: 27.1368408203125\n",
      "GI: 26.942691802978516\n",
      "D: 26.946292877197266\n",
      "GI: 26.938915252685547\n",
      "D: 26.93610191345215\n",
      "GI: 26.950302124023438\n",
      "D: 26.939496994018555\n",
      "GI: 26.946680068969727\n",
      "D: 26.931333541870117\n",
      "GI: 26.943883895874023\n",
      "D: 26.937591552734375\n",
      "GI: 26.936716079711914\n",
      "D: 26.941329956054688\n",
      "GI: 26.943450927734375\n",
      "D: 26.9330997467041\n",
      "GI: 26.925891876220703\n",
      "D: 26.945804595947266\n",
      "GI: 26.927154541015625\n",
      "D: 26.936641693115234\n",
      "GI: 26.907766342163086\n",
      "D: 26.931110382080078\n",
      "GI: 26.944108963012695\n",
      "D: 26.918224334716797\n",
      "GI: 26.942060470581055\n",
      "D: 26.927263259887695\n",
      "GI: 26.938873291015625\n",
      "D: 26.959138870239258\n",
      "GI: 26.937654495239258\n",
      "D: 26.92211151123047\n",
      "GI: 26.923307418823242\n",
      "D: 26.960264205932617\n",
      "GI: 26.936552047729492\n",
      "D: 26.9279727935791\n",
      "GI: 26.9129581451416\n",
      "D: 26.9408016204834\n",
      "GI: 26.937633514404297\n",
      "D: 26.923248291015625\n",
      "GI: 26.91982078552246\n",
      "D: 26.928829193115234\n",
      "GI: 26.963851928710938\n",
      "D: 26.93140983581543\n",
      "GI: 26.926429748535156\n",
      "D: 26.933063507080078\n",
      "GI: 26.90867042541504\n",
      "D: 26.932153701782227\n",
      "GI: 26.93779945373535\n",
      "D: 26.928512573242188\n",
      "GI: 26.936443328857422\n",
      "D: 26.933977127075195\n"
     ]
    }
   ],
   "source": [
    "# ************************\n",
    "# *** iWGANs Algorithm ***\n",
    "# ************************\n",
    "z_sample = torch.randn(batch_size, z_dim)\n",
    "z_sample = z_sample.cuda() if cuda_available else z_sample\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    data = iter(train_loader)\n",
    "    # 1. Update G, I network\n",
    "    # (1). Set up parameters of G, I to update\n",
    "    #      set up parameters of D to freeze\n",
    "    for p in netD.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in netI.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in netG.parameters():\n",
    "        p.requires_grad = True\n",
    "    # (2). Update G and I\n",
    "    for _ in range(critic_iter):\n",
    "        images, _ = next(data)\n",
    "        images = images.view(batch_size, 784)\n",
    "        real_data = images.cuda() if cuda_available else images\n",
    "        noise = torch.randn(batch_size, z_dim)\n",
    "        noise = noise.cuda() if cuda_available else noise\n",
    "        fake_data = netG(noise)\n",
    "        netI.zero_grad()\n",
    "        netG.zero_grad()\n",
    "        cost_GI = GI_loss(netI, netG, netD, real_data, fake_data)\n",
    "        images, _ = next(data)\n",
    "        x = images.view(batch_size, 784)\n",
    "        x = x.cuda() if cuda_available else x\n",
    "        z = torch.randn(batch_size, z_dim)\n",
    "        z = z.cuda() if cuda_available else z\n",
    "        z_hat = netI(x)\n",
    "        mmd = mmd_penalty(z_hat, z, kernel=\"IMQ\")\n",
    "        primal_cost = cost_GI + lambda_mmd * mmd\n",
    "        primal_cost.backward()\n",
    "        optim_I.step()\n",
    "        optim_G.step()\n",
    "    print('GI: '+str(primal(netI, netG, netD, real_data).cpu().item()))\n",
    "    # (3). Append primal and dual loss to list\n",
    "    primal_loss_GI.append(primal(netI, netG, netD, real_data).cpu().item())\n",
    "    dual_loss_GI.append(dual(netI, netG, netD, real_data, fake_data).cpu().item())\n",
    "    # 2. Update D network\n",
    "    # (1). Set up parameters of D to update\n",
    "    #      set up parameters of G, I to freeze\n",
    "    for p in netD.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in netI.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in netG.parameters():\n",
    "        p.requires_grad = False\n",
    "    # (2). Update D\n",
    "    for _ in range(critic_iter_d):\n",
    "#         _data = next(data)\n",
    "#         real_data = torch.Tensor(_data)\n",
    "#         real_data = real_data.cuda() if cuda_available else real_data\n",
    "        images, labels = next(data)\n",
    "        images = images.view(batch_size, 784)\n",
    "        real_data = images.cuda() if cuda_available else images\n",
    "        noise = torch.randn(batch_size, z_dim)\n",
    "        noise = noise.cuda() if cuda_available else noise\n",
    "        fake_data = netG(noise)\n",
    "        netD.zero_grad()\n",
    "        cost_D = D_loss(netI, netG, netD, real_data, fake_data)\n",
    "        images, _ = next(data)\n",
    "        x = images.view(batch_size, 784)\n",
    "        x = x.cuda() if cuda_available else x\n",
    "        z = torch.randn(batch_size, z_dim)\n",
    "        z = z.cuda() if cuda_available else z\n",
    "        z_hat = netI(x)\n",
    "        gp_D = gradient_penalty_dual(x.data, z.data, netD, netG, netI)\n",
    "        dual_cost = cost_D + lambda_gp * gp_D\n",
    "        dual_cost.backward()\n",
    "        optim_D.step()\n",
    "        loss_mmd.append(mmd.cpu().item())\n",
    "#         print(gp_D.cpu().item())\n",
    "    print('D: '+str(primal(netI, netG, netD, real_data).cpu().item()))\n",
    "    gp.append(gp_D.cpu().item())\n",
    "    re.append(primal(netI, netG, netD, real_data).cpu().item())\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        torchvision.utils.save_image(netG(z_sample).view(-1, 1, 28, 28)[:25], \"./outputs/MNIST/fake.png\", nrow=5)\n",
    "        torchvision.utils.save_image(images[:25], \"./outputs/MNIST/real.png\", nrow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(primal_loss_GI)\n",
    "# print(dual_loss_GI)\n",
    "# print(loss_mmd)\n",
    "# print(gp)\n",
    "# print(re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
