{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c393470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_16_1126\n"
     ]
    }
   ],
   "source": [
    "## load necessary modules\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.tools import *\n",
    "from utils.losses import *\n",
    "from models.cifar10 import *\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%m_%d_%H%M\")\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53617817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # check if gpu is available\n",
    "\n",
    "## load datasets\n",
    "# train_gen, dev_gen, test_gen = load(batch_size, batch_size)\n",
    "# data = inf_train_gen_mnist(train_gen)\n",
    "transform    = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),  # Normalize the image\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_gen    = dsets.CIFAR10(root=\"./datasets\",train=True, transform=transform, download=True)\n",
    "test_gen     = dsets.CIFAR10(root=\"./datasets\",train=False, transform=transform, download=True)\n",
    "# train_loader = DataLoader(train_gen, batch_size=batch_size, shuffle=True)\n",
    "# test_loader  = DataLoader(test_gen, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a1599a5-f845-4653-8753-d0c644d567ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper-parameters\n",
    "n_rep = 1\n",
    "epochs1 = 70\n",
    "epochs2 = 30\n",
    "std = 0.1\n",
    "lr_GI = 1e-4\n",
    "lr_D = 5e-4\n",
    "weight_decay = 0.01\n",
    "batch_size = 250\n",
    "z_dim = 5\n",
    "lambda_mmd = 1.0\n",
    "lambda_gp = 0.1\n",
    "lambda_power = 0.2\n",
    "eta = 3.0\n",
    "present_label = list(range(10))\n",
    "missing_label = []\n",
    "all_label     = present_label + missing_label\n",
    "classes       = train_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de72efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GI: 1.144873\n",
      "MMD: 0.022351\n",
      "D: -0.002342\n",
      "gp: 0.083201\n",
      "power: 0.222840\n",
      "GI: 0.861455\n",
      "MMD: 0.032856\n",
      "D: -0.001182\n",
      "gp: 0.081699\n",
      "power: 0.210729\n",
      "GI: 0.732750\n",
      "MMD: 0.023839\n",
      "D: -0.018673\n",
      "gp: 0.084783\n",
      "power: 0.196006\n",
      "GI: 0.656960\n",
      "MMD: 0.029777\n",
      "D: -0.023253\n",
      "gp: 0.084481\n",
      "power: 0.182653\n",
      "GI: 0.629430\n",
      "MMD: 0.020457\n",
      "D: -0.011703\n",
      "gp: 0.085584\n",
      "power: 0.179821\n",
      "GI: 0.625214\n",
      "MMD: 0.020502\n",
      "D: -0.042227\n",
      "gp: 0.075454\n",
      "power: 0.164620\n",
      "GI: 0.550818\n",
      "MMD: 0.025694\n",
      "D: -0.021140\n",
      "gp: 0.078590\n",
      "power: 0.160562\n",
      "GI: 0.621817\n",
      "MMD: 0.025842\n",
      "D: -0.061191\n",
      "gp: 0.077208\n",
      "power: 0.158691\n",
      "GI: 0.532500\n",
      "MMD: 0.030207\n",
      "D: -0.032460\n",
      "gp: 0.073779\n",
      "power: 0.149494\n",
      "GI: 0.542564\n",
      "MMD: 0.023767\n",
      "D: -0.066100\n",
      "gp: 0.078054\n",
      "power: 0.140824\n",
      "GI: 0.535765\n",
      "MMD: 0.025596\n",
      "D: -0.102516\n",
      "gp: 0.074854\n",
      "power: 0.141254\n",
      "GI: 0.457590\n",
      "MMD: 0.027578\n",
      "D: -0.075387\n",
      "gp: 0.079415\n",
      "power: 0.135380\n",
      "GI: 0.391673\n",
      "MMD: 0.020192\n",
      "D: -0.041276\n",
      "gp: 0.080159\n",
      "power: 0.124399\n",
      "GI: 0.432696\n",
      "MMD: 0.025203\n",
      "D: -0.148227\n",
      "gp: 0.080202\n",
      "power: 0.121018\n",
      "GI: 0.463569\n",
      "MMD: 0.023138\n",
      "D: -0.169122\n",
      "gp: 0.074106\n",
      "power: 0.120324\n",
      "GI: 0.436018\n",
      "MMD: 0.018669\n",
      "D: -0.142130\n",
      "gp: 0.079465\n",
      "power: 0.135238\n",
      "GI: 0.463226\n",
      "MMD: 0.040618\n",
      "D: -0.147221\n",
      "gp: 0.073057\n",
      "power: 0.150474\n",
      "GI: 0.446191\n",
      "MMD: 0.027360\n",
      "D: -0.143790\n",
      "gp: 0.080954\n",
      "power: 0.136854\n",
      "GI: 0.416173\n",
      "MMD: 0.028795\n",
      "D: -0.192327\n",
      "gp: 0.081425\n",
      "power: 0.137272\n",
      "GI: 0.353745\n",
      "MMD: 0.019508\n",
      "D: -0.043043\n",
      "gp: 0.079768\n",
      "power: 0.126584\n",
      "GI: 0.372070\n",
      "MMD: 0.026044\n",
      "D: -0.168637\n",
      "gp: 0.078414\n",
      "power: 0.127703\n",
      "GI: 0.483451\n",
      "MMD: 0.028552\n",
      "D: -0.055906\n",
      "gp: 0.070136\n",
      "power: 0.114307\n",
      "GI: 0.363812\n",
      "MMD: 0.018291\n",
      "D: -0.111825\n",
      "gp: 0.075707\n",
      "power: 0.118048\n",
      "GI: 0.415985\n",
      "MMD: 0.018654\n",
      "D: -0.167714\n",
      "gp: 0.068491\n",
      "power: 0.114542\n",
      "GI: 0.385727\n",
      "MMD: 0.038357\n",
      "D: -0.178011\n",
      "gp: 0.071125\n",
      "power: 0.104035\n",
      "GI: 0.323555\n",
      "MMD: 0.021096\n",
      "D: -0.112545\n",
      "gp: 0.070965\n",
      "power: 0.106474\n",
      "GI: 0.410809\n",
      "MMD: 0.019066\n",
      "D: -0.158823\n",
      "gp: 0.058543\n",
      "power: 0.100127\n",
      "GI: 0.373950\n",
      "MMD: 0.014519\n",
      "D: -0.081169\n",
      "gp: 0.058686\n",
      "power: 0.096886\n",
      "GI: 0.351178\n",
      "MMD: 0.009918\n",
      "D: -0.031176\n",
      "gp: 0.064871\n",
      "power: 0.087369\n",
      "GI: 0.254227\n",
      "MMD: 0.020794\n",
      "D: -0.181842\n",
      "gp: 0.070412\n",
      "power: 0.079472\n",
      "GI: 0.244359\n",
      "MMD: 0.007972\n",
      "D: -0.055562\n",
      "gp: 0.076085\n",
      "power: 0.082223\n",
      "GI: 0.295343\n",
      "MMD: 0.008049\n",
      "D: -0.077487\n",
      "gp: 0.065664\n",
      "power: 0.077982\n",
      "GI: 0.322122\n",
      "MMD: 0.013374\n",
      "D: -0.151814\n",
      "gp: 0.081033\n",
      "power: 0.069315\n",
      "GI: 0.303129\n",
      "MMD: 0.005276\n",
      "D: -0.167084\n",
      "gp: 0.079902\n",
      "power: 0.067281\n",
      "GI: 0.249373\n",
      "MMD: 0.001732\n",
      "D: -0.074271\n",
      "gp: 0.083944\n",
      "power: 0.065495\n",
      "GI: 0.311040\n",
      "MMD: 0.004074\n",
      "D: -0.040752\n",
      "gp: 0.075630\n",
      "power: 0.057693\n",
      "GI: 0.303086\n",
      "MMD: 0.003560\n",
      "D: -0.038023\n",
      "gp: 0.067881\n",
      "power: 0.052250\n",
      "GI: 0.267884\n",
      "MMD: 0.002691\n",
      "D: -0.118841\n",
      "gp: 0.070709\n",
      "power: 0.048709\n",
      "GI: 0.279004\n",
      "MMD: 0.001363\n",
      "D: -0.018158\n",
      "gp: 0.068249\n",
      "power: 0.046092\n",
      "GI: 0.276931\n",
      "MMD: 0.001174\n",
      "D: -0.026245\n",
      "gp: 0.067476\n",
      "power: 0.041601\n",
      "GI: 0.304848\n",
      "MMD: 0.003093\n",
      "D: -0.069986\n",
      "gp: 0.080298\n",
      "power: 0.039696\n",
      "GI: 0.242206\n",
      "MMD: 0.001400\n",
      "D: -0.049143\n",
      "gp: 0.077893\n",
      "power: 0.036570\n",
      "GI: 0.288033\n",
      "MMD: 0.001096\n",
      "D: -0.109166\n",
      "gp: 0.074274\n",
      "power: 0.037756\n",
      "GI: 0.271704\n",
      "MMD: 0.002102\n",
      "D: -0.184148\n",
      "gp: 0.086249\n",
      "power: 0.030509\n",
      "GI: 0.167366\n",
      "MMD: 0.001796\n",
      "D: -0.074263\n",
      "gp: 0.077349\n",
      "power: 0.028036\n",
      "GI: 0.286944\n",
      "MMD: 0.001219\n",
      "D: -0.036859\n",
      "gp: 0.072566\n",
      "power: 0.026054\n",
      "GI: 0.297968\n",
      "MMD: 0.001817\n",
      "D: -0.048874\n",
      "gp: 0.066169\n",
      "power: 0.025807\n",
      "GI: 0.259255\n",
      "MMD: 0.005195\n",
      "D: -0.038503\n",
      "gp: 0.067868\n",
      "power: 0.024163\n",
      "GI: 0.295222\n",
      "MMD: 0.001324\n",
      "D: -0.080440\n",
      "gp: 0.065082\n",
      "power: 0.022288\n",
      "GI: 0.246754\n",
      "MMD: 0.003252\n",
      "D: -0.069875\n",
      "gp: 0.066126\n",
      "power: 0.017949\n",
      "GI: 0.250172\n",
      "MMD: 0.001956\n",
      "D: -0.085764\n",
      "gp: 0.063580\n",
      "power: 0.020296\n",
      "GI: 0.210265\n",
      "MMD: 0.002538\n",
      "D: -0.155949\n",
      "gp: 0.088326\n",
      "power: 0.016684\n",
      "GI: 0.212631\n",
      "MMD: 0.001886\n",
      "D: -0.082760\n",
      "gp: 0.066729\n",
      "power: 0.016670\n",
      "GI: 0.248100\n",
      "MMD: 0.003836\n",
      "D: -0.061425\n",
      "gp: 0.066461\n",
      "power: 0.015318\n",
      "GI: 0.217610\n",
      "MMD: 0.001793\n",
      "D: -0.145916\n",
      "gp: 0.069756\n",
      "power: 0.018111\n",
      "GI: 0.224631\n",
      "MMD: 0.000422\n",
      "D: -0.090199\n",
      "gp: 0.068525\n",
      "power: 0.013973\n",
      "GI: 0.273512\n",
      "MMD: 0.004176\n",
      "D: -0.120626\n",
      "gp: 0.061533\n",
      "power: 0.014112\n",
      "GI: 0.202455\n",
      "MMD: 0.002244\n",
      "D: -0.055258\n",
      "gp: 0.072320\n",
      "power: 0.012847\n",
      "GI: 0.234833\n",
      "MMD: 0.001042\n",
      "D: -0.181102\n",
      "gp: 0.074056\n",
      "power: 0.011207\n",
      "GI: 0.119841\n",
      "MMD: 0.000537\n",
      "D: -0.161428\n",
      "gp: 0.070526\n",
      "power: 0.012396\n",
      "GI: 0.246341\n",
      "MMD: 0.006187\n",
      "D: -0.108418\n",
      "gp: 0.071273\n",
      "power: 0.013135\n",
      "GI: 0.196846\n",
      "MMD: 0.005636\n",
      "D: -0.152010\n",
      "gp: 0.077208\n",
      "power: 0.010063\n",
      "GI: 0.191786\n",
      "MMD: 0.000172\n",
      "D: -0.170700\n",
      "gp: 0.073184\n",
      "power: 0.010085\n",
      "GI: 0.171505\n",
      "MMD: 0.001206\n",
      "D: -0.143773\n",
      "gp: 0.080551\n",
      "power: 0.008073\n",
      "GI: 0.157734\n",
      "MMD: 0.002114\n",
      "D: -0.096548\n",
      "gp: 0.084832\n",
      "power: 0.009204\n",
      "GI: 0.197622\n",
      "MMD: 0.002310\n",
      "D: -0.086441\n",
      "gp: 0.066743\n",
      "power: 0.008614\n",
      "GI: 0.257971\n",
      "MMD: 0.002383\n",
      "D: -0.125722\n",
      "gp: 0.072043\n",
      "power: 0.006014\n",
      "GI: 0.184244\n",
      "MMD: 0.001688\n",
      "D: -0.073802\n",
      "gp: 0.074520\n",
      "power: 0.006469\n",
      "GI: 0.223403\n",
      "MMD: 0.002453\n",
      "D: -0.084943\n",
      "gp: 0.076116\n",
      "power: 0.006547\n",
      "GI: 0.220320\n",
      "MMD: 0.002611\n",
      "D: -0.188449\n",
      "gp: 0.084329\n",
      "power: 0.007262\n",
      "Class 4\n",
      "GI: 1.117297\n",
      "MMD: 0.027235\n",
      "D: -0.013953\n",
      "gp: 0.081947\n",
      "power: 0.198827\n",
      "GI: 0.906938\n",
      "MMD: 0.028194\n",
      "D: -0.016699\n",
      "gp: 0.080518\n",
      "power: 0.203581\n",
      "GI: 0.798945\n",
      "MMD: 0.030058\n",
      "D: -0.011361\n",
      "gp: 0.082493\n",
      "power: 0.193481\n",
      "GI: 0.720021\n",
      "MMD: 0.029498\n",
      "D: -0.009405\n",
      "gp: 0.079499\n",
      "power: 0.187050\n",
      "GI: 0.674468\n",
      "MMD: 0.037613\n",
      "D: -0.026375\n",
      "gp: 0.078302\n",
      "power: 0.172839\n",
      "GI: 0.585355\n",
      "MMD: 0.024207\n",
      "D: -0.036454\n",
      "gp: 0.076213\n",
      "power: 0.165252\n",
      "GI: 0.573857\n",
      "MMD: 0.021639\n",
      "D: -0.072686\n",
      "gp: 0.080032\n",
      "power: 0.146945\n",
      "GI: 0.521201\n",
      "MMD: 0.028561\n",
      "D: -0.029807\n",
      "gp: 0.077089\n",
      "power: 0.148844\n",
      "GI: 0.515574\n",
      "MMD: 0.019183\n",
      "D: -0.041796\n",
      "gp: 0.073833\n",
      "power: 0.141968\n",
      "GI: 0.535908\n",
      "MMD: 0.018162\n",
      "D: -0.060250\n",
      "gp: 0.073463\n",
      "power: 0.137957\n",
      "GI: 0.478984\n",
      "MMD: 0.022616\n",
      "D: -0.058405\n",
      "gp: 0.077791\n",
      "power: 0.130979\n",
      "GI: 0.433259\n",
      "MMD: 0.014667\n",
      "D: -0.023955\n",
      "gp: 0.075657\n",
      "power: 0.125023\n",
      "GI: 0.412771\n",
      "MMD: 0.026681\n",
      "D: -0.079144\n",
      "gp: 0.070272\n",
      "power: 0.114433\n",
      "GI: 0.401735\n",
      "MMD: 0.015442\n",
      "D: -0.021102\n",
      "gp: 0.079031\n",
      "power: 0.111253\n",
      "GI: 0.394282\n",
      "MMD: 0.019594\n",
      "D: -0.032730\n",
      "gp: 0.073560\n",
      "power: 0.098967\n",
      "GI: 0.409964\n",
      "MMD: 0.014393\n",
      "D: -0.018721\n",
      "gp: 0.071435\n",
      "power: 0.094909\n",
      "GI: 0.405889\n",
      "MMD: 0.024731\n",
      "D: -0.108361\n",
      "gp: 0.079802\n",
      "power: 0.086236\n",
      "GI: 0.326856\n",
      "MMD: 0.001665\n",
      "D: -0.009236\n",
      "gp: 0.072060\n",
      "power: 0.084003\n",
      "GI: 0.408226\n",
      "MMD: 0.014686\n",
      "D: -0.030171\n",
      "gp: 0.075171\n",
      "power: 0.081407\n",
      "GI: 0.356788\n",
      "MMD: 0.007482\n",
      "D: -0.012653\n",
      "gp: 0.074643\n",
      "power: 0.069296\n",
      "GI: 0.381661\n",
      "MMD: 0.003712\n",
      "D: -0.038564\n",
      "gp: 0.069896\n",
      "power: 0.065055\n",
      "GI: 0.263941\n",
      "MMD: 0.007653\n",
      "D: -0.012953\n",
      "gp: 0.073866\n",
      "power: 0.056625\n",
      "GI: 0.335186\n",
      "MMD: 0.006004\n",
      "D: -0.056658\n",
      "gp: 0.070952\n",
      "power: 0.056164\n",
      "GI: 0.328399\n",
      "MMD: 0.001202\n",
      "D: -0.032182\n",
      "gp: 0.080158\n",
      "power: 0.041145\n",
      "GI: 0.295822\n",
      "MMD: 0.004138\n",
      "D: -0.048045\n",
      "gp: 0.078634\n",
      "power: 0.043704\n",
      "GI: 0.362510\n",
      "MMD: 0.001357\n",
      "D: -0.105356\n",
      "gp: 0.072704\n",
      "power: 0.039859\n",
      "GI: 0.281227\n",
      "MMD: 0.000580\n",
      "D: -0.055684\n",
      "gp: 0.074173\n",
      "power: 0.034518\n",
      "GI: 0.246374\n",
      "MMD: 0.002437\n",
      "D: -0.059604\n",
      "gp: 0.080866\n",
      "power: 0.031870\n",
      "GI: 0.280274\n",
      "MMD: 0.002734\n",
      "D: -0.054901\n",
      "gp: 0.074129\n",
      "power: 0.034902\n",
      "GI: 0.270740\n",
      "MMD: 0.001666\n",
      "D: -0.093702\n",
      "gp: 0.071304\n",
      "power: 0.031263\n",
      "GI: 0.240530\n",
      "MMD: 0.002482\n",
      "D: -0.125667\n",
      "gp: 0.084723\n",
      "power: 0.027470\n",
      "GI: 0.224175\n",
      "MMD: 0.002850\n",
      "D: -0.022907\n",
      "gp: 0.074519\n",
      "power: 0.025545\n",
      "GI: 0.349877\n",
      "MMD: -0.000469\n",
      "D: -0.063521\n",
      "gp: 0.079755\n",
      "power: 0.023312\n",
      "GI: 0.296905\n",
      "MMD: 0.001614\n",
      "D: -0.049631\n",
      "gp: 0.083382\n",
      "power: 0.021399\n",
      "GI: 0.276209\n",
      "MMD: 0.001983\n",
      "D: -0.040284\n",
      "gp: 0.071945\n",
      "power: 0.019890\n",
      "GI: 0.276456\n",
      "MMD: 0.002043\n",
      "D: -0.015706\n",
      "gp: 0.081756\n",
      "power: 0.015715\n",
      "GI: 0.244126\n",
      "MMD: 0.001004\n",
      "D: -0.068595\n",
      "gp: 0.085686\n",
      "power: 0.016973\n",
      "GI: 0.261423\n",
      "MMD: 0.002585\n",
      "D: 0.001129\n",
      "gp: 0.072307\n",
      "power: 0.013972\n",
      "GI: 0.260665\n",
      "MMD: 0.003153\n",
      "D: -0.049704\n",
      "gp: 0.101379\n",
      "power: 0.014128\n",
      "GI: 0.240710\n",
      "MMD: 0.001377\n",
      "D: -0.048751\n",
      "gp: 0.084981\n",
      "power: 0.015718\n",
      "GI: 0.299140\n",
      "MMD: 0.004984\n",
      "D: -0.098246\n",
      "gp: 0.076252\n",
      "power: 0.012234\n",
      "GI: 0.296324\n",
      "MMD: 0.001845\n",
      "D: -0.032096\n",
      "gp: 0.076938\n",
      "power: 0.012235\n",
      "GI: 0.306682\n",
      "MMD: 0.001297\n",
      "D: -0.089636\n",
      "gp: 0.078526\n",
      "power: 0.009467\n",
      "GI: 0.271796\n",
      "MMD: 0.002583\n",
      "D: -0.040882\n",
      "gp: 0.074556\n",
      "power: 0.008525\n",
      "GI: 0.230261\n",
      "MMD: 0.001843\n",
      "D: -0.065499\n",
      "gp: 0.084243\n",
      "power: 0.010160\n",
      "GI: 0.224039\n",
      "MMD: 0.000814\n",
      "D: -0.081105\n",
      "gp: 0.077487\n",
      "power: 0.008175\n",
      "GI: 0.253460\n",
      "MMD: 0.000323\n",
      "D: -0.072508\n",
      "gp: 0.085952\n",
      "power: 0.009830\n",
      "GI: 0.256585\n",
      "MMD: 0.001079\n",
      "D: -0.051729\n",
      "gp: 0.068218\n",
      "power: 0.008862\n",
      "GI: 0.238632\n",
      "MMD: 0.004142\n",
      "D: -0.117497\n",
      "gp: 0.084867\n",
      "power: 0.007776\n",
      "GI: 0.219555\n",
      "MMD: 0.001069\n",
      "D: -0.043776\n",
      "gp: 0.074353\n",
      "power: 0.007627\n",
      "GI: 0.228911\n",
      "MMD: 0.000118\n",
      "D: -0.029688\n",
      "gp: 0.077820\n",
      "power: 0.006995\n",
      "GI: 0.244525\n",
      "MMD: 0.004465\n",
      "D: -0.088116\n",
      "gp: 0.067568\n",
      "power: 0.006530\n",
      "GI: 0.190084\n",
      "MMD: 0.004264\n",
      "D: -0.135737\n",
      "gp: 0.176167\n",
      "power: 0.006454\n",
      "GI: 0.174570\n",
      "MMD: 0.001471\n",
      "D: -0.053659\n",
      "gp: 0.077141\n",
      "power: 0.006173\n",
      "GI: 0.235243\n",
      "MMD: 0.001987\n",
      "D: -0.030495\n",
      "gp: 0.084495\n",
      "power: 0.004775\n",
      "GI: 0.261221\n",
      "MMD: 0.008739\n",
      "D: -0.061563\n",
      "gp: 0.079959\n",
      "power: 0.007644\n",
      "GI: 0.212566\n",
      "MMD: 0.003195\n",
      "D: -0.021702\n",
      "gp: 0.071772\n",
      "power: 0.007000\n",
      "GI: 0.179253\n",
      "MMD: 0.000911\n",
      "D: -0.028669\n",
      "gp: 0.075567\n",
      "power: 0.004593\n",
      "GI: 0.235492\n",
      "MMD: 0.001588\n",
      "D: -0.052397\n",
      "gp: 0.072432\n",
      "power: 0.004683\n",
      "GI: 0.211673\n",
      "MMD: 0.002428\n",
      "D: -0.035088\n",
      "gp: 0.077947\n",
      "power: 0.003463\n",
      "GI: 0.239437\n",
      "MMD: 0.001330\n",
      "D: -0.052886\n",
      "gp: 0.069760\n",
      "power: 0.004330\n",
      "GI: 0.257118\n",
      "MMD: 0.003859\n",
      "D: -0.068563\n",
      "gp: 0.071040\n",
      "power: 0.004772\n",
      "GI: 0.180945\n",
      "MMD: 0.000631\n",
      "D: -0.073660\n",
      "gp: 0.073361\n",
      "power: 0.003223\n",
      "GI: 0.176286\n",
      "MMD: 0.001321\n",
      "D: -0.077981\n",
      "gp: 0.071468\n",
      "power: 0.005901\n",
      "GI: 0.212259\n",
      "MMD: 0.001584\n",
      "D: -0.020442\n",
      "gp: 0.077372\n",
      "power: 0.003606\n",
      "GI: 0.245621\n",
      "MMD: 0.004157\n",
      "D: -0.074675\n",
      "gp: 0.070512\n",
      "power: 0.003213\n",
      "GI: 0.268237\n",
      "MMD: 0.000843\n",
      "D: -0.092649\n",
      "gp: 0.074935\n",
      "power: 0.003486\n",
      "GI: 0.179096\n",
      "MMD: 0.007886\n",
      "D: -0.049861\n",
      "gp: 0.068520\n",
      "power: 0.003042\n",
      "GI: 0.166912\n",
      "MMD: 0.002932\n",
      "D: -0.089184\n",
      "gp: 0.079921\n",
      "power: 0.002222\n",
      "GI: 0.204039\n",
      "MMD: 0.003013\n",
      "D: -0.072459\n",
      "gp: 0.079336\n",
      "power: 0.005265\n",
      "Class 5\n",
      "GI: 1.162176\n",
      "MMD: 0.018391\n",
      "D: -0.000617\n",
      "gp: 0.081737\n",
      "power: 0.220993\n",
      "GI: 0.879302\n",
      "MMD: 0.023328\n",
      "D: -0.006574\n",
      "gp: 0.081569\n",
      "power: 0.216380\n",
      "GI: 0.816218\n",
      "MMD: 0.029736\n",
      "D: -0.014818\n",
      "gp: 0.084669\n",
      "power: 0.202643\n",
      "GI: 0.695255\n",
      "MMD: 0.031827\n",
      "D: -0.019853\n",
      "gp: 0.083408\n",
      "power: 0.188548\n",
      "GI: 0.627234\n",
      "MMD: 0.027096\n",
      "D: -0.051332\n",
      "gp: 0.085560\n",
      "power: 0.173369\n",
      "GI: 0.607322\n",
      "MMD: 0.021651\n",
      "D: -0.043763\n",
      "gp: 0.091844\n",
      "power: 0.173934\n",
      "GI: 0.622333\n",
      "MMD: 0.019295\n",
      "D: -0.047539\n",
      "gp: 0.094556\n",
      "power: 0.175145\n",
      "GI: 0.591496\n",
      "MMD: 0.029020\n",
      "D: -0.073630\n",
      "gp: 0.092510\n",
      "power: 0.162575\n",
      "GI: 0.619604\n",
      "MMD: 0.018402\n",
      "D: -0.078015\n",
      "gp: 0.092033\n",
      "power: 0.152283\n",
      "GI: 0.546745\n",
      "MMD: 0.023793\n",
      "D: -0.095580\n",
      "gp: 0.093232\n",
      "power: 0.153701\n",
      "GI: 0.503408\n",
      "MMD: 0.017995\n",
      "D: -0.087396\n",
      "gp: 0.095996\n",
      "power: 0.142389\n",
      "GI: 0.523085\n",
      "MMD: 0.013254\n",
      "D: -0.069328\n",
      "gp: 0.096154\n",
      "power: 0.137567\n",
      "GI: 0.518987\n",
      "MMD: 0.015193\n",
      "D: -0.104214\n",
      "gp: 0.091614\n",
      "power: 0.135750\n",
      "GI: 0.566788\n",
      "MMD: 0.012767\n",
      "D: -0.087125\n",
      "gp: 0.093149\n",
      "power: 0.125869\n",
      "GI: 0.558425\n",
      "MMD: 0.012764\n",
      "D: -0.117008\n",
      "gp: 0.097160\n",
      "power: 0.116115\n",
      "GI: 0.511625\n",
      "MMD: 0.018260\n",
      "D: -0.138300\n",
      "gp: 0.093440\n",
      "power: 0.118243\n",
      "GI: 0.493306\n",
      "MMD: 0.013918\n",
      "D: -0.108560\n",
      "gp: 0.096349\n",
      "power: 0.108521\n",
      "GI: 0.544390\n",
      "MMD: 0.010336\n",
      "D: -0.152158\n",
      "gp: 0.093347\n",
      "power: 0.104006\n",
      "GI: 0.549029\n",
      "MMD: 0.009769\n",
      "D: -0.152615\n",
      "gp: 0.093505\n",
      "power: 0.097643\n",
      "GI: 0.517680\n",
      "MMD: 0.019784\n",
      "D: -0.151246\n",
      "gp: 0.092725\n",
      "power: 0.097095\n",
      "GI: 0.573255\n",
      "MMD: 0.009632\n",
      "D: -0.109804\n",
      "gp: 0.108486\n",
      "power: 0.092223\n",
      "GI: 0.543130\n",
      "MMD: 0.014443\n",
      "D: -0.139061\n",
      "gp: 0.096575\n",
      "power: 0.085739\n",
      "GI: 0.583664\n",
      "MMD: 0.006905\n",
      "D: -0.176513\n",
      "gp: 0.098747\n",
      "power: 0.088425\n",
      "GI: 0.498793\n",
      "MMD: 0.031456\n",
      "D: -0.147630\n",
      "gp: 0.086769\n",
      "power: 0.093377\n",
      "GI: 0.529898\n",
      "MMD: 0.018490\n",
      "D: -0.081541\n",
      "gp: 0.093823\n",
      "power: 0.083330\n",
      "GI: 0.459107\n",
      "MMD: 0.011637\n",
      "D: -0.128578\n",
      "gp: 0.096890\n",
      "power: 0.072508\n",
      "GI: 0.472541\n",
      "MMD: 0.013916\n",
      "D: -0.144948\n",
      "gp: 0.092900\n",
      "power: 0.073316\n",
      "GI: 0.444925\n",
      "MMD: 0.018194\n",
      "D: -0.147706\n",
      "gp: 0.085211\n",
      "power: 0.068621\n",
      "GI: 0.523247\n",
      "MMD: 0.013293\n",
      "D: -0.109770\n",
      "gp: 0.093054\n",
      "power: 0.062255\n",
      "GI: 0.514000\n",
      "MMD: 0.012696\n",
      "D: -0.161304\n",
      "gp: 0.095815\n",
      "power: 0.057617\n",
      "GI: 0.470924\n",
      "MMD: 0.005704\n",
      "D: -0.171483\n",
      "gp: 0.089127\n",
      "power: 0.054770\n",
      "GI: 0.303640\n",
      "MMD: 0.014862\n",
      "D: 0.011041\n",
      "gp: 0.080117\n",
      "power: 0.057500\n",
      "GI: 0.318760\n",
      "MMD: 0.008266\n",
      "D: 0.045700\n",
      "gp: 0.086049\n",
      "power: 0.055362\n",
      "GI: 0.338327\n",
      "MMD: 0.007926\n",
      "D: 0.019492\n",
      "gp: 0.082107\n",
      "power: 0.050347\n",
      "GI: 0.354956\n",
      "MMD: 0.005009\n",
      "D: 0.032084\n",
      "gp: 0.082229\n",
      "power: 0.043112\n",
      "GI: 0.310013\n",
      "MMD: 0.004979\n",
      "D: -0.000616\n",
      "gp: 0.090858\n",
      "power: 0.043750\n",
      "GI: 0.289926\n",
      "MMD: 0.006148\n",
      "D: 0.014196\n",
      "gp: 0.082181\n",
      "power: 0.036950\n",
      "GI: 0.262174\n",
      "MMD: 0.003096\n",
      "D: 0.041025\n",
      "gp: 0.082018\n",
      "power: 0.034286\n",
      "GI: 0.286008\n",
      "MMD: 0.002775\n",
      "D: -0.007138\n",
      "gp: 0.081515\n",
      "power: 0.031736\n",
      "GI: 0.299055\n",
      "MMD: 0.006118\n",
      "D: 0.019601\n",
      "gp: 0.073695\n",
      "power: 0.028311\n",
      "GI: 0.258356\n",
      "MMD: 0.003648\n",
      "D: 0.007474\n",
      "gp: 0.084729\n",
      "power: 0.027773\n",
      "GI: 0.312879\n",
      "MMD: 0.004048\n",
      "D: 0.010542\n",
      "gp: 0.075514\n",
      "power: 0.023769\n",
      "GI: 0.283062\n",
      "MMD: 0.002305\n",
      "D: -0.008195\n",
      "gp: 0.081289\n",
      "power: 0.024392\n",
      "GI: 0.251242\n",
      "MMD: 0.006585\n",
      "D: -0.018600\n",
      "gp: 0.085265\n",
      "power: 0.025629\n",
      "GI: 0.259687\n",
      "MMD: 0.003090\n",
      "D: -0.002232\n",
      "gp: 0.081272\n",
      "power: 0.023126\n",
      "GI: 0.311678\n",
      "MMD: 0.002283\n",
      "D: 0.002391\n",
      "gp: 0.082353\n",
      "power: 0.020113\n",
      "GI: 0.334624\n",
      "MMD: 0.001282\n",
      "D: -0.007957\n",
      "gp: 0.085068\n",
      "power: 0.018517\n",
      "GI: 0.272887\n",
      "MMD: 0.003176\n",
      "D: 0.010279\n",
      "gp: 0.078066\n",
      "power: 0.016497\n",
      "GI: 0.241392\n",
      "MMD: 0.003190\n",
      "D: 0.027507\n",
      "gp: 0.078012\n",
      "power: 0.014632\n",
      "GI: 0.280964\n",
      "MMD: 0.002098\n",
      "D: 0.030678\n",
      "gp: 0.074869\n",
      "power: 0.015607\n",
      "GI: 0.258783\n",
      "MMD: 0.002717\n",
      "D: 0.025321\n",
      "gp: 0.077517\n",
      "power: 0.014873\n",
      "GI: 0.214571\n",
      "MMD: 0.003626\n",
      "D: -0.014561\n",
      "gp: 0.081816\n",
      "power: 0.011871\n",
      "GI: 0.222053\n",
      "MMD: 0.001979\n",
      "D: 0.005972\n",
      "gp: 0.075999\n",
      "power: 0.012104\n",
      "GI: 0.273132\n",
      "MMD: 0.001490\n",
      "D: -0.010491\n",
      "gp: 0.078965\n",
      "power: 0.011177\n",
      "GI: 0.263009\n",
      "MMD: 0.001224\n",
      "D: 0.011795\n",
      "gp: 0.073244\n",
      "power: 0.008433\n",
      "GI: 0.308112\n",
      "MMD: 0.001379\n",
      "D: -0.005974\n",
      "gp: 0.075387\n",
      "power: 0.009560\n",
      "GI: 0.274808\n",
      "MMD: 0.003572\n",
      "D: -0.023042\n",
      "gp: 0.077181\n",
      "power: 0.009199\n",
      "GI: 0.303180\n",
      "MMD: 0.002822\n",
      "D: -0.018163\n",
      "gp: 0.077022\n",
      "power: 0.011861\n",
      "GI: 0.217396\n",
      "MMD: 0.002699\n",
      "D: -0.006813\n",
      "gp: 0.075090\n",
      "power: 0.008817\n",
      "GI: 0.238411\n",
      "MMD: 0.002448\n",
      "D: -0.007873\n",
      "gp: 0.079394\n",
      "power: 0.008006\n",
      "GI: 0.207645\n",
      "MMD: 0.001506\n",
      "D: 0.020498\n",
      "gp: 0.077408\n",
      "power: 0.006361\n",
      "GI: 0.248180\n",
      "MMD: 0.001873\n",
      "D: 0.005720\n",
      "gp: 0.074819\n",
      "power: 0.005824\n",
      "GI: 0.193315\n",
      "MMD: 0.003242\n",
      "D: 0.002241\n",
      "gp: 0.076859\n",
      "power: 0.008424\n",
      "GI: 0.213452\n",
      "MMD: 0.005065\n",
      "D: 0.006395\n",
      "gp: 0.077591\n",
      "power: 0.005700\n",
      "GI: 0.276893\n",
      "MMD: 0.009329\n",
      "D: -0.021061\n",
      "gp: 0.075065\n",
      "power: 0.004896\n",
      "GI: 0.197353\n",
      "MMD: 0.003913\n",
      "D: -0.003943\n",
      "gp: 0.078876\n",
      "power: 0.004893\n",
      "GI: 0.228780\n",
      "MMD: 0.003516\n",
      "D: -0.011005\n",
      "gp: 0.081655\n",
      "power: 0.006246\n",
      "GI: 0.192975\n",
      "MMD: 0.002205\n",
      "D: 0.023149\n",
      "gp: 0.075339\n",
      "power: 0.004634\n",
      "GI: 0.200455\n",
      "MMD: 0.004091\n",
      "D: 0.005345\n",
      "gp: 0.081731\n",
      "power: 0.003426\n",
      "GI: 0.203946\n",
      "MMD: 0.004498\n",
      "D: 0.015730\n",
      "gp: 0.078569\n",
      "power: 0.004124\n",
      "Class 6\n",
      "GI: 1.064078\n",
      "MMD: 0.020704\n",
      "D: -0.003272\n",
      "gp: 0.077014\n",
      "power: 0.237834\n",
      "GI: 0.918297\n",
      "MMD: 0.021040\n",
      "D: -0.019725\n",
      "gp: 0.077930\n",
      "power: 0.217341\n",
      "GI: 0.725467\n",
      "MMD: 0.022142\n",
      "D: -0.000186\n",
      "gp: 0.083412\n",
      "power: 0.202536\n",
      "GI: 0.706180\n",
      "MMD: 0.028964\n",
      "D: -0.023643\n",
      "gp: 0.081623\n",
      "power: 0.194649\n",
      "GI: 0.588054\n",
      "MMD: 0.019642\n",
      "D: -0.046791\n",
      "gp: 0.095396\n",
      "power: 0.176609\n",
      "GI: 0.652612\n",
      "MMD: 0.020524\n",
      "D: -0.061956\n",
      "gp: 0.089057\n",
      "power: 0.175700\n",
      "GI: 0.538758\n",
      "MMD: 0.016773\n",
      "D: -0.058499\n",
      "gp: 0.089131\n",
      "power: 0.205545\n",
      "GI: 0.620243\n",
      "MMD: 0.037617\n",
      "D: -0.090662\n",
      "gp: 0.079546\n",
      "power: 0.206729\n",
      "GI: 0.640769\n",
      "MMD: 0.038060\n",
      "D: -0.124272\n",
      "gp: 0.077283\n",
      "power: 0.207158\n",
      "GI: 0.648512\n",
      "MMD: 0.044650\n",
      "D: -0.147564\n",
      "gp: 0.100234\n",
      "power: 0.209667\n",
      "GI: 0.631768\n",
      "MMD: 0.043804\n",
      "D: -0.125493\n",
      "gp: 0.098146\n",
      "power: 0.203502\n",
      "GI: 0.702788\n",
      "MMD: 0.038201\n",
      "D: -0.090839\n",
      "gp: 0.079860\n",
      "power: 0.200612\n",
      "GI: 0.513230\n",
      "MMD: 0.040554\n",
      "D: -0.143304\n",
      "gp: 0.077902\n",
      "power: 0.205629\n",
      "GI: 0.640352\n",
      "MMD: 0.046504\n",
      "D: -0.145579\n",
      "gp: 0.084883\n",
      "power: 0.201445\n",
      "GI: 0.672614\n",
      "MMD: 0.033770\n",
      "D: -0.171182\n",
      "gp: 0.088993\n",
      "power: 0.200747\n",
      "GI: 0.578615\n",
      "MMD: 0.037916\n",
      "D: -0.156465\n",
      "gp: 0.082658\n",
      "power: 0.202381\n",
      "GI: 0.547151\n",
      "MMD: 0.046004\n",
      "D: -0.124953\n",
      "gp: 0.080319\n",
      "power: 0.199675\n",
      "GI: 0.489986\n",
      "MMD: 0.038872\n",
      "D: -0.170819\n",
      "gp: 0.082620\n",
      "power: 0.210219\n",
      "GI: 0.538958\n",
      "MMD: 0.040044\n",
      "D: -0.177219\n",
      "gp: 0.077126\n",
      "power: 0.209468\n",
      "GI: 0.541163\n",
      "MMD: 0.045062\n",
      "D: -0.103174\n",
      "gp: 0.073247\n",
      "power: 0.199260\n",
      "GI: 0.474675\n",
      "MMD: 0.039353\n",
      "D: -0.101393\n",
      "gp: 0.076381\n",
      "power: 0.209934\n",
      "GI: 0.565668\n",
      "MMD: 0.038432\n",
      "D: -0.103592\n",
      "gp: 0.077217\n",
      "power: 0.207617\n",
      "GI: 0.497220\n",
      "MMD: 0.036450\n",
      "D: -0.137020\n",
      "gp: 0.080081\n",
      "power: 0.206014\n",
      "GI: 0.443259\n",
      "MMD: 0.027813\n",
      "D: 0.013784\n",
      "gp: 0.066820\n",
      "power: 0.209380\n",
      "GI: 0.506624\n",
      "MMD: 0.019943\n",
      "D: -0.090437\n",
      "gp: 0.055215\n",
      "power: 0.215234\n",
      "GI: 0.426304\n",
      "MMD: 0.023499\n",
      "D: -0.022920\n",
      "gp: 0.059415\n",
      "power: 0.209758\n",
      "GI: 0.496300\n",
      "MMD: 0.023207\n",
      "D: -0.054311\n",
      "gp: 0.058156\n",
      "power: 0.216345\n",
      "GI: 0.433041\n",
      "MMD: 0.022506\n",
      "D: -0.034788\n",
      "gp: 0.056625\n",
      "power: 0.209442\n",
      "GI: 0.456716\n",
      "MMD: 0.025619\n",
      "D: -0.059611\n",
      "gp: 0.063219\n",
      "power: 0.203694\n",
      "GI: 0.442831\n",
      "MMD: 0.024774\n",
      "D: -0.059953\n",
      "gp: 0.059831\n",
      "power: 0.204037\n",
      "GI: 0.429382\n",
      "MMD: 0.023361\n",
      "D: -0.066665\n",
      "gp: 0.079772\n",
      "power: 0.205112\n",
      "GI: 0.420256\n",
      "MMD: 0.017848\n",
      "D: -0.097088\n",
      "gp: 0.080110\n",
      "power: 0.199733\n",
      "GI: 0.361494\n",
      "MMD: 0.017444\n",
      "D: -0.086861\n",
      "gp: 0.056940\n",
      "power: 0.197052\n",
      "GI: 0.371725\n",
      "MMD: 0.022649\n",
      "D: -0.024620\n",
      "gp: 0.054953\n",
      "power: 0.197947\n",
      "GI: 0.391335\n",
      "MMD: 0.025851\n",
      "D: -0.088557\n",
      "gp: 0.067668\n",
      "power: 0.210531\n",
      "GI: 0.379600\n",
      "MMD: 0.020717\n",
      "D: -0.098046\n",
      "gp: 0.058368\n",
      "power: 0.195839\n",
      "GI: 0.397901\n",
      "MMD: 0.032400\n",
      "D: -0.059737\n",
      "gp: 0.051616\n",
      "power: 0.193847\n",
      "GI: 0.387919\n",
      "MMD: 0.028600\n",
      "D: -0.059497\n",
      "gp: 0.095418\n",
      "power: 0.199076\n",
      "GI: 0.362917\n",
      "MMD: 0.022850\n",
      "D: -0.149447\n",
      "gp: 0.064137\n",
      "power: 0.191959\n",
      "GI: 0.392665\n",
      "MMD: 0.032458\n",
      "D: -0.036899\n",
      "gp: 0.077508\n",
      "power: 0.190822\n",
      "GI: 0.338331\n",
      "MMD: 0.028069\n",
      "D: -0.145784\n",
      "gp: 0.078983\n",
      "power: 0.187367\n",
      "GI: 0.266018\n",
      "MMD: 0.022675\n",
      "D: -0.070954\n",
      "gp: 0.069485\n",
      "power: 0.188239\n",
      "GI: 0.345412\n",
      "MMD: 0.029345\n",
      "D: -0.027858\n",
      "gp: 0.049486\n",
      "power: 0.184210\n",
      "GI: 0.373981\n",
      "MMD: 0.027514\n",
      "D: -0.086621\n",
      "gp: 0.085889\n",
      "power: 0.198390\n",
      "GI: 0.382067\n",
      "MMD: 0.030210\n",
      "D: -0.063610\n",
      "gp: 0.047497\n",
      "power: 0.189596\n",
      "GI: 0.322148\n",
      "MMD: 0.028877\n",
      "D: -0.081251\n",
      "gp: 0.058527\n",
      "power: 0.191308\n",
      "GI: 0.315333\n",
      "MMD: 0.024144\n",
      "D: -0.048331\n",
      "gp: 0.059296\n",
      "power: 0.184737\n",
      "GI: 0.345848\n",
      "MMD: 0.019678\n",
      "D: -0.047627\n",
      "gp: 0.057689\n",
      "power: 0.183235\n",
      "GI: 0.364010\n",
      "MMD: 0.023276\n",
      "D: -0.034882\n",
      "gp: 0.056947\n",
      "power: 0.181341\n",
      "GI: 0.338462\n",
      "MMD: 0.026809\n",
      "D: -0.100539\n",
      "gp: 0.062063\n",
      "power: 0.187976\n",
      "GI: 0.289794\n",
      "MMD: 0.023295\n",
      "D: -0.067365\n",
      "gp: 0.056671\n",
      "power: 0.178792\n",
      "GI: 0.290843\n",
      "MMD: 0.032652\n",
      "D: -0.046847\n",
      "gp: 0.071985\n",
      "power: 0.186564\n",
      "GI: 0.312156\n",
      "MMD: 0.029835\n",
      "D: -0.053739\n",
      "gp: 0.068564\n",
      "power: 0.176355\n",
      "GI: 0.313508\n",
      "MMD: 0.023850\n",
      "D: -0.028747\n",
      "gp: 0.064048\n",
      "power: 0.181154\n",
      "GI: 0.330551\n",
      "MMD: 0.027064\n",
      "D: -0.024484\n",
      "gp: 0.060759\n",
      "power: 0.174102\n",
      "GI: 0.300171\n",
      "MMD: 0.022042\n",
      "D: -0.032973\n",
      "gp: 0.061531\n",
      "power: 0.178140\n",
      "GI: 0.366186\n",
      "MMD: 0.034448\n",
      "D: -0.038848\n",
      "gp: 0.050833\n",
      "power: 0.168184\n",
      "GI: 0.350574\n",
      "MMD: 0.021353\n",
      "D: -0.044554\n",
      "gp: 0.054500\n",
      "power: 0.169437\n",
      "GI: 0.307586\n",
      "MMD: 0.031645\n",
      "D: -0.064839\n",
      "gp: 0.083406\n",
      "power: 0.179911\n",
      "GI: 0.265612\n",
      "MMD: 0.029855\n",
      "D: -0.067503\n",
      "gp: 0.054461\n",
      "power: 0.177406\n",
      "GI: 0.390109\n",
      "MMD: 0.034516\n",
      "D: -0.053681\n",
      "gp: 0.052311\n",
      "power: 0.172687\n",
      "GI: 0.205020\n",
      "MMD: 0.030611\n",
      "D: -0.083238\n",
      "gp: 0.075394\n",
      "power: 0.166366\n",
      "GI: 0.268107\n",
      "MMD: 0.035320\n",
      "D: -0.051122\n",
      "gp: 0.070940\n",
      "power: 0.162095\n",
      "GI: 0.308573\n",
      "MMD: 0.030047\n",
      "D: -0.032573\n",
      "gp: 0.057637\n",
      "power: 0.166719\n",
      "GI: 0.347898\n",
      "MMD: 0.027627\n",
      "D: 0.004347\n",
      "gp: 0.051176\n",
      "power: 0.165403\n",
      "GI: 0.285365\n",
      "MMD: 0.025013\n",
      "D: -0.058121\n",
      "gp: 0.065758\n",
      "power: 0.176771\n",
      "GI: 0.309033\n",
      "MMD: 0.029504\n",
      "D: -0.085175\n",
      "gp: 0.079168\n",
      "power: 0.167283\n",
      "GI: 0.230941\n",
      "MMD: 0.023963\n",
      "D: -0.042543\n",
      "gp: 0.056976\n",
      "power: 0.171708\n",
      "GI: 0.352809\n",
      "MMD: 0.032678\n",
      "D: -0.027857\n",
      "gp: 0.078309\n",
      "power: 0.161289\n",
      "GI: 0.342234\n",
      "MMD: 0.024521\n",
      "D: -0.036656\n",
      "gp: 0.062711\n",
      "power: 0.167513\n",
      "Class 8\n"
     ]
    }
   ],
   "source": [
    "# ************************\n",
    "# *** DPI-RG Algorithm ***\n",
    "# ************************\n",
    "\n",
    "cover_accs = []\n",
    "avg_counts = []\n",
    "\n",
    "# for rep in range(n_rep):\n",
    "T_trains = []\n",
    "for lab in present_label:\n",
    "    ## initialize models\n",
    "    netI = I_CIFAR10(nz=z_dim)\n",
    "    netG = G_CIFAR10(nz=z_dim)\n",
    "    netD = D_CIFAR10(nz=z_dim)\n",
    "    netI = netI.to(device)\n",
    "    netG = netG.to(device)\n",
    "    netD = netD.to(device)\n",
    "    netI = nn.DataParallel(netI)\n",
    "    netG = nn.DataParallel(netG)\n",
    "    netD = nn.DataParallel(netD)\n",
    "\n",
    "    ## set up optimizers\n",
    "    optim_I = optim.Adam(netI.parameters(), lr=lr_GI, betas=(0.5, 0.999))\n",
    "    optim_G = optim.Adam(netG.parameters(), lr=lr_GI, betas=(0.5, 0.999))\n",
    "    optim_D = optim.Adam(netD.parameters(), lr=lr_D, betas=(0.5, 0.999), \n",
    "                         weight_decay=weight_decay)\n",
    "    ## filter data for each label and train them respectively\n",
    "    if torch.is_tensor(train_gen.targets):\n",
    "        idxs = torch.where(train_gen.targets == lab)[0] \n",
    "    else:\n",
    "        idxs = torch.where(torch.Tensor(train_gen.targets) == lab)[0] \n",
    "    train_data = torch.utils.data.Subset(train_gen, idxs)\n",
    "    train_loader  = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    ## train for the first time\n",
    "    train_al(netI, netG, netD, optim_I, optim_G, optim_D,\n",
    "             train_gen, train_loader, batch_size, 0, epochs1, \n",
    "             z_dim, device, lab, present_label, all_label, \n",
    "             lambda_gp, lambda_power, lambda_mmd = lambda_mmd,\n",
    "             img_size = 32, nc = 3, eta = eta, \n",
    "             lr_decay = None, trace=True)\n",
    "\n",
    "    ## find out fake_zs\n",
    "    fake_zs = []\n",
    "    with torch.no_grad(): \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            x, _ = batch\n",
    "            fake_z = netI(x.to(device))\n",
    "            fake_zs.append(fake_z)\n",
    "    fake_zs = torch.cat(fake_zs)\n",
    "    ## get the empirical distribution for each label\n",
    "    T_train = torch.sqrt(torch.sum(fake_zs ** 2, dim=1) + 1)\n",
    "\n",
    "    ## get powers to determine new sample sizes\n",
    "    powers = []\n",
    "    for cur_lab in present_label:    \n",
    "        if cur_lab != lab:\n",
    "            # fake_Cs for this class\n",
    "            if torch.is_tensor(train_gen.targets):\n",
    "                idxs3 = torch.where(train_gen.targets == cur_lab)[0] \n",
    "            else:\n",
    "                idxs3 = torch.where(torch.Tensor(train_gen.targets) == cur_lab)[0] \n",
    "            train_data3 = torch.utils.data.Subset(train_gen, idxs3)\n",
    "            train_loader3  = DataLoader(train_data3, batch_size=batch_size, shuffle=False)\n",
    "            p_vals = torch.zeros(len(idxs3)) \n",
    "            fake_zs = torch.zeros(len(idxs3))\n",
    "            em_len = len(T_train)\n",
    "\n",
    "            for i, batch in enumerate(train_loader3):\n",
    "                x, _ = batch\n",
    "                fake_z = netI(x.to(device))\n",
    "                T_batch = torch.sqrt(torch.sum(fake_z ** 2, dim=1) + 1)\n",
    "\n",
    "                # compute p-value for each sample\n",
    "                for j in range(len(fake_z)):\n",
    "                    p1 = torch.sum(T_train > T_batch[j]) / em_len\n",
    "                    p = p1\n",
    "                    # calculate the p-value and put it in the corresponding list\n",
    "                    p_vals[i * batch_size + j] = p.item()\n",
    "            powers.append(np.sum(np.array(p_vals) <= 0.05) / len(idxs3))\n",
    "            \n",
    "    sample_sizes = max(powers) - powers + 0.05\n",
    "    sample_sizes = (sample_sizes / sum(sample_sizes) * len(idxs3)).astype(int)\n",
    "    # print(sample_sizes)\n",
    "    ## train for the second time according to the calculated sample sizes\n",
    "    train_al(netI, netG, netD, optim_I, optim_G, optim_D,\n",
    "             train_gen, train_loader, batch_size, epochs1, epochs2, \n",
    "             z_dim, device, lab, present_label, all_label, \n",
    "             lambda_gp, lambda_power, lambda_mmd = lambda_mmd, sample_sizes = sample_sizes, \n",
    "             img_size = 32, nc = 3, eta = eta, \n",
    "             lr_decay = None, trace = True)\n",
    "    \n",
    "    ## find out fake_zs\n",
    "    fake_zs = []\n",
    "    with torch.no_grad(): \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            x, _ = batch\n",
    "            fake_z = netI(x.to(device))\n",
    "            fake_zs.append(fake_z)\n",
    "    fake_zs = torch.cat(fake_zs)\n",
    "    ## get the empirical distribution for each label\n",
    "    T_train = torch.sqrt(torch.sum(fake_zs ** 2, dim=1) + 1)\n",
    "    T_trains.append(T_train)\n",
    "\n",
    "    ## save net and graphs for each label\n",
    "    model_save_file = f'cifar10_param/{timestamp}_class{lab}.pt'\n",
    "    torch.save(netI.state_dict(), model_save_file)\n",
    "    del netI\n",
    "    print('Class', lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ef165e1-7090-454d-ac94-d74eec332227",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m p_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(present_label), \u001b[38;5;28mlen\u001b[39m(idxs2)) \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pidx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(present_label)):\n\u001b[0;32m---> 18\u001b[0m     T_train \u001b[38;5;241m=\u001b[39m T_trains[pidx]\n\u001b[1;32m     19\u001b[0m     em_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(T_train)\n\u001b[1;32m     20\u001b[0m     netI \u001b[38;5;241m=\u001b[39m I_CIFAR10(nz\u001b[38;5;241m=\u001b[39mz_dim)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# training for verification\n",
    "all_p_vals  = []\n",
    "all_fake_Ts = []\n",
    "\n",
    "for lab in all_label:    \n",
    "    if torch.is_tensor(train_gen.targets):\n",
    "        idxs2 = torch.where(train_gen.targets == lab)[0] \n",
    "    else:\n",
    "        idxs2 = torch.where(torch.Tensor(train_gen.targets) == lab)[0] \n",
    "    test_data = torch.utils.data.Subset(train_gen, idxs2)\n",
    "    test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # p_vals and fake_zs store p-values, fake_zs for the current iteration\n",
    "    fake_Ts = torch.zeros(len(present_label), len(idxs2))\n",
    "    p_vals = torch.zeros(len(present_label), len(idxs2)) \n",
    "\n",
    "    for pidx in range(len(present_label)):\n",
    "        T_train = T_trains[pidx]\n",
    "        em_len = len(T_train)\n",
    "        netI = I_CIFAR10(nz=z_dim)\n",
    "        netI = netI.to(device)\n",
    "        netI = torch.nn.DataParallel(netI)\n",
    "        model_save_file = f'cifar10_param/{timestamp}_class{present_label[pidx]}.pt'\n",
    "        netI.load_state_dict(torch.load(model_save_file))\n",
    "        \n",
    "        for i, batch in enumerate(test_loader):\n",
    "            images, y = batch\n",
    "            x = images.view(-1, 3, 32 * 32).to(device)\n",
    "            fake_z = netI(x)\n",
    "            T_batch = torch.sqrt(torch.sum(torch.square(fake_z), 1) + 1) \n",
    "            ## compute p-value for each sample\n",
    "            for j in range(len(fake_z)):\n",
    "                p1 = torch.sum(T_train > T_batch[j]) / em_len\n",
    "                p = p1\n",
    "                # calculate the p-value and put it in the corresponding list\n",
    "                fake_Ts[pidx, i * batch_size + j] = T_batch[j].item()\n",
    "                p_vals[pidx, i * batch_size + j] = p.item()\n",
    "\n",
    "    all_p_vals.append(np.array(p_vals))\n",
    "    ## concatenate torch data\n",
    "    all_fake_Ts.append(np.array(fake_Ts))\n",
    "    # print('Finished Label {}'.format(lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f792c4-8887-4ab4-a9f3-77df261e4f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f6b7f-a433-41e2-9de5-f313748dd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_T(all_fake_Ts, present_label, all_label, missing_label, z_dim, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5650706-a3e7-47f2-ace7-4d4dd0c340dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_p(all_p_vals, present_label, all_label, missing_label, z_dim, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bb3e3-7301-4263-a533-21e56b982358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data set\n",
    "all_p_vals  = []\n",
    "all_fake_Ts = []\n",
    "\n",
    "for lab in all_label:    \n",
    "    if torch.is_tensor(test_gen.targets):\n",
    "        idxs2 = torch.where(test_gen.targets == lab)[0] \n",
    "    else:\n",
    "        idxs2 = torch.where(torch.Tensor(test_gen.targets) == lab)[0] \n",
    "    test_data = torch.utils.data.Subset(test_gen, idxs2)\n",
    "    test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # p_vals and fake_zs store p-values, fake_zs for the current iteration\n",
    "    fake_Ts = torch.zeros(len(present_label), len(idxs2))\n",
    "    p_vals = torch.zeros(len(present_label), len(idxs2)) \n",
    "\n",
    "    for pidx in range(len(present_label)):\n",
    "        T_train = T_trains[pidx]\n",
    "        em_len = len(T_train)\n",
    "        netI = I_CIFAR10(nz=z_dim)\n",
    "        netI = netI.to(device)\n",
    "        netI = torch.nn.DataParallel(netI)\n",
    "        model_save_file = f'cifar10_param/{timestamp}_class{present_label[pidx]}.pt'\n",
    "        netI.load_state_dict(torch.load(model_save_file))\n",
    "        \n",
    "        for i, batch in enumerate(test_loader):\n",
    "            images, y = batch\n",
    "            x = images.view(-1, 3, 32 * 32).to(device)\n",
    "            fake_z = netI(x)\n",
    "            T_batch = torch.sqrt(torch.sum(torch.square(fake_z), 1) + 1) \n",
    "            ## compute p-value for each sample\n",
    "            for j in range(len(fake_z)):\n",
    "                p1 = torch.sum(T_train > T_batch[j]) / em_len\n",
    "                p = p1\n",
    "                # calculate the p-value and put it in the corresponding list\n",
    "                fake_Ts[pidx, i * batch_size + j] = T_batch[j].item()\n",
    "                p_vals[pidx, i * batch_size + j] = p.item()\n",
    "\n",
    "    all_p_vals.append(np.array(p_vals))\n",
    "    ## concatenate torch data\n",
    "    all_fake_Ts.append(np.array(fake_Ts))\n",
    "    # print('Finished Label {}'.format(lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a96a0-c2e2-4ccc-8c8a-8d9314de1c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_T(all_fake_Ts, present_label, all_label, missing_label, z_dim, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b7d2a-f2b7-41c5-adbe-140aa48529af",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_p(all_p_vals, present_label, all_label, missing_label, z_dim, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c52517-29f4-472f-9064-2ae64561f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_accs = []\n",
    "avg_counts = []\n",
    "\n",
    "cover_acc = torch.zeros(len(all_label))\n",
    "avg_count = torch.zeros(len(all_label))\n",
    "for i, lab in enumerate(all_label):\n",
    "    p_vals = all_p_vals[i]\n",
    "    n = p_vals.shape[1]\n",
    "    cover = 0.0\n",
    "    counts = 0.0\n",
    "    for j in range(n):\n",
    "        pred = np.argmax(p_vals[:, j])\n",
    "        p_set = np.where(p_vals[:, j] > 0.05)[0]\n",
    "        counts += len(p_set)\n",
    "        if lab in missing_label:\n",
    "            if len(p_set) == 0:\n",
    "                cover += 1\n",
    "        else:\n",
    "            if all_label[i] in p_set:\n",
    "                cover += 1\n",
    "    cover_acc[i] = cover / n\n",
    "    avg_count[i] = counts / n\n",
    "cover_accs.append(cover_acc)\n",
    "avg_counts.append(avg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e53b5406-c586-4155-beb6-766ecb8a4575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0.9730, 0.8690, 0.9530, 0.9390, 0.9370, 0.9580, 0.9460, 0.9550, 0.9140,\n",
      "        0.9500])]\n",
      "[tensor([3.8330, 4.0980, 4.3980, 3.7430, 3.6970, 3.8000, 4.5480, 3.5420, 3.7370,\n",
      "        4.0930])]\n"
     ]
    }
   ],
   "source": [
    "print(cover_accs)\n",
    "print(avg_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
