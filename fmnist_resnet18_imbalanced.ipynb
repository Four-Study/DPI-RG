{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c393470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024_02_13_1212\n"
     ]
    }
   ],
   "source": [
    "## load necessary modules\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.tools import *\n",
    "from utils.losses import *\n",
    "from models.mnist import *\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%m_%d_%H%M\")\n",
    "timestamp = '2024_02_13_1212'\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53617817",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "# torch.manual_seed(random_seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # check if gpu is available\n",
    "\n",
    "## load datasets\n",
    "transform    = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_gen    = dsets.FashionMNIST(root=\"./datasets\",train=True, transform=transform, download=True)\n",
    "test_gen     = dsets.FashionMNIST(root=\"./datasets\",train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "## initial empty lists for training progress\n",
    "# primal_loss_GI = []\n",
    "# dual_loss_GI = []\n",
    "# primal_loss = []\n",
    "# dual_loss = []\n",
    "# primal_loss_z = []\n",
    "# loss_mmd = []\n",
    "# gp = []\n",
    "# re = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1599a5-f845-4653-8753-d0c644d567ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper-parameters\n",
    "n_rep = 20\n",
    "epochs1 = 50\n",
    "epochs2 = 50\n",
    "std = 0.1\n",
    "lr_GI = 5e-4\n",
    "lr_D = 5e-4 * 5\n",
    "weight_decay = 0.01\n",
    "batch_size = 250\n",
    "z_dim = 5\n",
    "lambda_mmd = 2.0\n",
    "lambda_gp = 0.1\n",
    "lambda_power = 1.5\n",
    "eta = 2.5\n",
    "dirichlet_alpha = 3.0\n",
    "present_label = list(range(10))\n",
    "missing_label = []\n",
    "all_label     = present_label + missing_label\n",
    "classes       = train_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2be210-4761-4378-b702-c226ed2839c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3647 5484 8784 6420 8182 7264 1649 8615 6827 3128]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "# Step 1: Generate Dirichlet distribution weights\n",
    "weights = np.random.dirichlet([dirichlet_alpha] * len(present_label))\n",
    "# Step 2: Calculate the number of samples for each class\n",
    "total_samples = len(train_gen.data)\n",
    "samples_per_class = np.round(weights * total_samples).astype(int)\n",
    "# Adjust to make sure the total is equal to the original test set size\n",
    "samples_per_class[-1] = total_samples - np.sum(samples_per_class[:-1])\n",
    "sampled_idxs = []\n",
    "for idx, lab in enumerate(present_label):    \n",
    "    if torch.is_tensor(train_gen.targets):\n",
    "        class_idxs = torch.where(train_gen.targets == lab)[0] \n",
    "    else:\n",
    "        class_idxs = torch.where(torch.Tensor(train_gen.targets) == lab)[0] \n",
    "    temp = np.random.choice(class_idxs, size=samples_per_class[idx], replace=True)\n",
    "    sampled_idxs.append(torch.Tensor(temp).int())\n",
    "print(samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de72efba",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/Git/FPI/models/mnist.py\", line 53, in forward\n    return super(I_MNIST, self).forward(x)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torchvision/models/resnet.py\", line 285, in forward\n    return self._forward_impl(x)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torchvision/models/resnet.py\", line 271, in _forward_impl\n    x = self.maxpool(x)\n        ^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 166, in forward\n    return F.max_pool2d(input, self.kernel_size, self.stride,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/_jit_internal.py\", line 488, in fn\n    return if_false(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py\", line 791, in _max_pool2d\n    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 15.52 GiB of which 7.00 MiB is free. Process 1644479 has 260.00 MiB memory in use. Process 1553784 has 14.76 GiB memory in use. Including non-PyTorch memory, this process has 478.00 MiB memory in use. Of the allocated memory 70.31 MiB is allocated by PyTorch, and 35.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 93\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     92\u001b[0m         x, _ \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 93\u001b[0m         fake_z \u001b[38;5;241m=\u001b[39m netI(x\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     94\u001b[0m         fake_zs\u001b[38;5;241m.\u001b[39mappend(fake_z)\n\u001b[1;32m     95\u001b[0m fake_zs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(fake_zs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(replicas)])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:110\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    108\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 110\u001b[0m         output\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m    111\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/Git/FPI/models/mnist.py\", line 53, in forward\n    return super(I_MNIST, self).forward(x)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torchvision/models/resnet.py\", line 285, in forward\n    return self._forward_impl(x)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torchvision/models/resnet.py\", line 271, in _forward_impl\n    x = self.maxpool(x)\n        ^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 166, in forward\n    return F.max_pool2d(input, self.kernel_size, self.stride,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/_jit_internal.py\", line 488, in fn\n    return if_false(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/youhui/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py\", line 791, in _max_pool2d\n    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 15.52 GiB of which 7.00 MiB is free. Process 1644479 has 260.00 MiB memory in use. Process 1553784 has 14.76 GiB memory in use. Including non-PyTorch memory, this process has 478.00 MiB memory in use. Of the allocated memory 70.31 MiB is allocated by PyTorch, and 35.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "# ************************\n",
    "# *** DPI-RG Algorithm ***\n",
    "# ************************\n",
    "\n",
    "cover_accs = []\n",
    "avg_counts = []\n",
    "\n",
    "# for rep in range(n_rep):\n",
    "T_trains = []\n",
    "for lab in present_label:\n",
    "    ## initialize models\n",
    "    netI = I_MNIST(nz=z_dim)\n",
    "    netG = G_MNIST(nz=z_dim)\n",
    "    netD = D_MNIST(nz=z_dim)\n",
    "    netI = netI.to(device)\n",
    "    netG = netG.to(device)\n",
    "    netD = netD.to(device)\n",
    "    netI = nn.DataParallel(netI)\n",
    "    netG = nn.DataParallel(netG)\n",
    "    netD = nn.DataParallel(netD)\n",
    "    model_save_file = f'fmnist_param/{timestamp}_class{lab}.pt'\n",
    "    netI.load_state_dict(torch.load(model_save_file))\n",
    "\n",
    "    # ## set up optimizers\n",
    "    # optim_I = optim.Adam(netI.parameters(), lr=lr_GI, betas=(0.5, 0.999))\n",
    "    # optim_G = optim.Adam(netG.parameters(), lr=lr_GI, betas=(0.5, 0.999))\n",
    "    # optim_D = optim.Adam(netD.parameters(), lr=lr_D,  betas=(0.5, 0.999), \n",
    "    #                      weight_decay=weight_decay)\n",
    "    ## filter data for each label and train them respectively\n",
    "    train_data = torch.utils.data.Subset(train_gen, sampled_idxs[lab])\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # ## train for the first time\n",
    "    # train_al(netI, netG, netD, optim_I, optim_G, optim_D,\n",
    "    #          train_gen, train_loader, batch_size, 0, epochs1, \n",
    "    #          z_dim, device, lab, present_label, all_label, \n",
    "    #          lambda_gp, lambda_power, lambda_mmd = lambda_mmd, eta = eta, \n",
    "    #          sampled_idxs = sampled_idxs, trace=True)\n",
    "    # ## find out fake_zs\n",
    "    # fake_zs = []\n",
    "    # with torch.no_grad(): \n",
    "    #     for i, batch in enumerate(train_loader):\n",
    "    #         x, _ = batch\n",
    "    #         fake_z = netI(x.to(device))\n",
    "    #         fake_zs.append(fake_z)\n",
    "    # fake_zs = torch.cat(fake_zs)\n",
    "    # ## get the empirical distribution for each label\n",
    "    # T_train = torch.sqrt(torch.sum(fake_zs ** 2, dim=1) + 1)\n",
    "\n",
    "    # ## get powers to determine new sample sizes\n",
    "    # powers = []\n",
    "    # for cur_lab in present_label:    \n",
    "    #     if cur_lab != lab:\n",
    "    #         # fake_Cs for this class\n",
    "    #         # if torch.is_tensor(train_gen.targets):\n",
    "    #         #     idxs3 = torch.where(train_gen.targets == cur_lab)[0] \n",
    "    #         # else:\n",
    "    #         #     idxs3 = torch.where(torch.Tensor(train_gen.targets) == cur_lab)[0] \n",
    "    #         idxs3 = sampled_idxs[cur_lab]\n",
    "    #         train_data3 = torch.utils.data.Subset(train_gen, idxs3)\n",
    "    #         train_loader3  = DataLoader(train_data3, batch_size=batch_size, shuffle=False)\n",
    "    #         p_vals = torch.zeros(len(idxs3)) \n",
    "    #         fake_zs = torch.zeros(len(idxs3))\n",
    "    #         em_len = len(T_train)\n",
    "\n",
    "    #         for i, batch in enumerate(train_loader3):\n",
    "    #             x, _ = batch\n",
    "    #             fake_z = netI(x.to(device))\n",
    "    #             T_batch = torch.sqrt(torch.sum(fake_z ** 2, dim=1) + 1)\n",
    "\n",
    "    #             # compute p-value for each sample\n",
    "    #             for j in range(len(fake_z)):\n",
    "    #                 p1 = torch.sum(T_train > T_batch[j]) / em_len\n",
    "    #                 p = p1\n",
    "    #                 # calculate the p-value and put it in the corresponding list\n",
    "    #                 p_vals[i * batch_size + j] = p.item()\n",
    "    #         powers.append(np.sum(np.array(p_vals) <= 0.05) / len(idxs3))\n",
    "            \n",
    "    # sample_sizes = max(powers) - powers + 0.05\n",
    "    # sample_sizes = (sample_sizes / sum(sample_sizes) * len(sampled_idxs[lab])).astype(int)\n",
    "    # ## train for the second time according to the calculated sample sizes\n",
    "    # train_al(netI, netG, netD, optim_I, optim_G, optim_D,\n",
    "    #          train_gen, train_loader, batch_size, epochs1, epochs2, \n",
    "    #          z_dim, device, lab, present_label, all_label, \n",
    "    #          lambda_gp, lambda_power, lambda_mmd = lambda_mmd, eta = eta, \n",
    "    #          sample_sizes = sample_sizes, sampled_idxs = sampled_idxs, trace=True)\n",
    "    \n",
    "    ## find out fake_zs\n",
    "    fake_zs = []\n",
    "    with torch.no_grad(): \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            x, _ = batch\n",
    "            fake_z = netI(x.to(device))\n",
    "            fake_zs.append(fake_z)\n",
    "    fake_zs = torch.cat(fake_zs)\n",
    "    ## get the empirical distribution for each label\n",
    "    T_train = torch.sqrt(torch.sum(fake_zs ** 2, dim=1) + 1)\n",
    "    T_trains.append(T_train)\n",
    "\n",
    "    ## save net and graphs for each label\n",
    "    # model_save_file = f'fmnist_param/{timestamp}_class{lab}.pt'\n",
    "    # torch.save(netI.state_dict(), model_save_file)\n",
    "    del netI\n",
    "    print(f'Class {lab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bb3e3-7301-4263-a533-21e56b982358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test data set\n",
    "# all_p_vals  = []\n",
    "# all_fake_Ts = []\n",
    "\n",
    "# for lab in all_label:    \n",
    "#     if torch.is_tensor(test_gen.targets):\n",
    "#         idxs2 = torch.where(test_gen.targets == lab)[0] \n",
    "#     else:\n",
    "#         idxs2 = torch.where(torch.Tensor(test_gen.targets) == lab)[0] \n",
    "#     test_data = torch.utils.data.Subset(test_gen, idxs2)\n",
    "#     test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     # p_vals and fake_zs store p-values, fake_zs for the current iteration\n",
    "#     fake_Ts = torch.zeros(len(present_label), len(idxs2))\n",
    "#     p_vals = torch.zeros(len(present_label), len(idxs2)) \n",
    "\n",
    "#     for pidx in range(len(present_label)):\n",
    "#         T_train = T_trains[pidx]\n",
    "#         em_len = len(T_train)\n",
    "#         netI = I_MNIST(nz=z_dim)\n",
    "#         netI = netI.to(device)\n",
    "#         netI = torch.nn.DataParallel(netI)\n",
    "#         model_save_file = f'fmnist_param/{timestamp}_class{present_label[pidx]}.pt'\n",
    "#         netI.load_state_dict(torch.load(model_save_file))\n",
    "        \n",
    "#         for i, batch in enumerate(test_loader):\n",
    "#             images, y = batch\n",
    "#             x = images.view(-1, 1, 28 * 28).to(device)\n",
    "#             fake_z = netI(x)\n",
    "#             T_batch = torch.sqrt(torch.sum(torch.square(fake_z), 1) + 1) \n",
    "#             ## compute p-value for each sample\n",
    "#             for j in range(len(fake_z)):\n",
    "#                 p1 = torch.sum(T_train > T_batch[j]) / em_len\n",
    "#                 p = p1\n",
    "#                 # calculate the p-value and put it in the corresponding list\n",
    "#                 fake_Ts[pidx, i * batch_size + j] = T_batch[j].item()\n",
    "#                 p_vals[pidx, i * batch_size + j] = p.item()\n",
    "\n",
    "#     all_p_vals.append(np.array(p_vals))\n",
    "#     ## concatenate torch data\n",
    "#     all_fake_Ts.append(np.array(fake_Ts))\n",
    "#     # print('Finished Label {}'.format(lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac230279-10d7-48dc-b453-3edbea7283a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_fake_T(all_fake_Ts, present_label, all_label, missing_label, z_dim, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b7d2a-f2b7-41c5-adbe-140aa48529af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_p(all_p_vals, present_label, all_label, missing_label, z_dim, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c52517-29f4-472f-9064-2ae64561f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_accs = []\n",
    "avg_errors = []\n",
    "\n",
    "for rep in range(n_rep):\n",
    "    # Step 1: Generate Dirichlet distribution weights\n",
    "    weights = np.random.dirichlet([dirichlet_alpha] * len(all_label))\n",
    "    # Step 2: Calculate the number of samples for each class\n",
    "    total_samples = len(test_gen.data)\n",
    "    samples_per_class = np.round(weights * total_samples).astype(int)\n",
    "    # Adjust to make sure the total is equal to the original test set size\n",
    "    samples_per_class[-1] = total_samples - np.sum(samples_per_class[:-1])\n",
    "\n",
    "    ## test data set\n",
    "    all_p_vals  = []\n",
    "    all_fake_Ts = []\n",
    "    \n",
    "    for lab in all_label:    \n",
    "        if torch.is_tensor(test_gen.targets):\n",
    "            idxs2 = torch.where(test_gen.targets == lab)[0] \n",
    "        else:\n",
    "            idxs2 = torch.where(torch.Tensor(test_gen.targets) == lab)[0] \n",
    "        test_data = torch.utils.data.Subset(test_gen, idxs2)\n",
    "        test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "        # p_vals and fake_zs store p-values, fake_zs for the current iteration\n",
    "        fake_Ts = torch.zeros(len(present_label), len(idxs2))\n",
    "        p_vals = torch.zeros(len(present_label), len(idxs2)) \n",
    "    \n",
    "        for pidx in range(len(present_label)):\n",
    "            T_train = T_trains[pidx]\n",
    "            em_len = len(T_train)\n",
    "            netI = I_MNIST(nz=z_dim)\n",
    "            netI = netI.to(device)\n",
    "            netI = torch.nn.DataParallel(netI)\n",
    "            model_save_file = f'fmnist_param/{timestamp}_class{present_label[pidx]}.pt'\n",
    "            netI.load_state_dict(torch.load(model_save_file))\n",
    "            \n",
    "            for i, batch in enumerate(test_loader):\n",
    "                images, y = batch\n",
    "                x = images.view(-1, 1, 28 * 28).to(device)\n",
    "                fake_z = netI(x)\n",
    "                T_batch = torch.sqrt(torch.sum(torch.square(fake_z), 1) + 1) \n",
    "                ## compute p-value for each sample\n",
    "                for j in range(len(fake_z)):\n",
    "                    p1 = torch.sum(T_train > T_batch[j]) / em_len\n",
    "                    p = p1\n",
    "                    # calculate the p-value and put it in the corresponding list\n",
    "                    fake_Ts[pidx, i * batch_size + j] = T_batch[j].item()\n",
    "                    p_vals[pidx, i * batch_size + j] = p.item()\n",
    "    \n",
    "        all_p_vals.append(np.array(p_vals))\n",
    "        ## concatenate torch data\n",
    "        all_fake_Ts.append(np.array(fake_Ts))\n",
    "        # print('Finished Label {}'.format(lab))\n",
    "    \n",
    "    # cover_acc = torch.zeros(len(all_label))\n",
    "    # avg_error = torch.zeros(len(all_label))\n",
    "    cover = 0.0\n",
    "    error = 0.0\n",
    "    for i, lab in enumerate(all_label):\n",
    "        p_vals = all_p_vals[i]\n",
    "        n = p_vals.shape[1]\n",
    "        for j in range(n):\n",
    "            pred = np.argmax(p_vals[:, j])\n",
    "            p_set = np.where(p_vals[:, j] > 0.05)[0]\n",
    "            # counts += len(p_set)\n",
    "            if lab in missing_label:\n",
    "                error += len(p_set)\n",
    "                if len(p_set) == 0:\n",
    "                    cover += 1\n",
    "            else:\n",
    "                error += abs(len(p_set) - 1) \n",
    "                if all_label[i] in p_set:\n",
    "                    cover += 1\n",
    "        # cover_acc[i] = cover / n \n",
    "        # avg_error[i] = error / n \n",
    "    cover_acc = cover / total_samples \n",
    "    avg_error = error / total_samples \n",
    "    cover_accs.append(cover_acc)\n",
    "    avg_errors.append(avg_error)\n",
    "    print(f'rep = {rep+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b5406-c586-4155-beb6-766ecb8a4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(cover_accs))\n",
    "print(np.mean(avg_errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
